{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock Analysis: ORCL\n",
        "\n",
        "This notebook analyzes volume patterns and inefficiencies for ORCL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Install required packages\n",
        "!pip install pandas numpy matplotlib seaborn google-cloud-bigquery pandas-gbq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.cloud import bigquery\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Authenticate with Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Configuration\n",
        "TICKER = \"ORCL\"  # Will be replaced with actual ticker\n",
        "PROJECT_ID = \"delphi-449908\"  # Will be replaced with actual project ID\n",
        "DATASET = \"trading_insights\"\n",
        "DIRECTION = \"buy\"  # Will be replaced with 'buy' or 'short'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fetch data from BigQuery\n",
        "query = f\"\"\"\n",
        "SELECT *\n",
        "FROM `delphi-449908.{DATASET}.stock_ORCL_prices`\n",
        "ORDER BY date DESC\n",
        "LIMIT 252  -- Approximately 1 year of trading days\n",
        "\"\"\"\n",
        "\n",
        "df = client.query(query).to_dataframe()\n",
        "\n",
        "# Convert date to datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Sort by date\n",
        "df = df.sort_values('date')\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Loaded {len(df)} rows of data for ORCL\")\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume Analysis\n",
        "\n",
        "We'll analyze volume patterns to identify potential inefficiencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Calculate volume metrics\n",
        "df['volume_ma20'] = df['volume'].rolling(window=20).mean()\n",
        "df['volume_std20'] = df['volume'].rolling(window=20).std()\n",
        "df['volume_ratio'] = df['volume'] / df['volume_ma20']\n",
        "df['volume_z_score'] = (df['volume'] - df['volume_ma20']) / df['volume_std20']\n",
        "\n",
        "# Identify volume spikes (Z-score > 2.0)\n",
        "df['is_volume_spike'] = df['volume_z_score'] > 2.0\n",
        "\n",
        "# Calculate price change\n",
        "df['price_change'] = df['close'].pct_change() * 100\n",
        "\n",
        "# Display summary\n",
        "print(f\"Number of volume spikes: {df['is_volume_spike'].sum()}\")\n",
        "df[df['is_volume_spike']].tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Visualize volume and price\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "# Plot price\n",
        "ax1.plot(df['date'], df['close'], label='Close Price')\n",
        "ax1.set_title(f'ORCL Price', fontsize=16)\n",
        "ax1.set_ylabel('Price ($)', fontsize=14)\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Plot volume\n",
        "ax2.bar(df['date'], df['volume'], color='blue', alpha=0.5, label='Volume')\n",
        "ax2.plot(df['date'], df['volume_ma20'], color='red', label='20-day MA')\n",
        "\n",
        "# Highlight volume spikes\n",
        "spike_dates = df[df['is_volume_spike']]['date']\n",
        "spike_volumes = df[df['is_volume_spike']]['volume']\n",
        "ax2.scatter(spike_dates, spike_volumes, color='red', s=50, label='Volume Spike')\n",
        "\n",
        "ax2.set_title(f'ORCL Volume', fontsize=16)\n",
        "ax2.set_ylabel('Volume', fontsize=14)\n",
        "ax2.set_xlabel('Date', fontsize=14)\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Volume Spike Analysis\n",
        "\n",
        "Let's analyze what happens after volume spikes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Function to calculate forward returns\n",
        "def calculate_forward_returns(df, days=[1, 3, 5, 10]):\n",
        "    for day in days:\n",
        "        df[f'return_{day}d'] = df['close'].pct_change(periods=day).shift(-day) * 100\n",
        "    return df\n",
        "\n",
        "# Calculate forward returns\n",
        "df = calculate_forward_returns(df)\n",
        "\n",
        "# Analyze returns after volume spikes\n",
        "spike_returns = df[df['is_volume_spike']].copy()\n",
        "\n",
        "# Display average returns after spikes\n",
        "print(\"Average returns after volume spikes:\")\n",
        "for day in [1, 3, 5, 10]:\n",
        "    avg_return = spike_returns[f'return_{day}d'].mean()\n",
        "    print(f\"{day}-day return: {avg_return:.2f}%\")\n",
        "\n",
        "# Display recent volume spikes\n",
        "recent_spikes = spike_returns.tail(5)\n",
        "recent_spikes[['date', 'close', 'volume', 'volume_z_score', 'return_1d', 'return_3d', 'return_5d']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Signal Generation\n",
        "\n",
        "Based on volume analysis, let's generate trading signals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Generate signals based on volume spikes\n",
        "def generate_signals(df, direction):\n",
        "    signals = []\n",
        "    \n",
        "    # Get recent volume spikes\n",
        "    recent_spikes = df[df['is_volume_spike']].tail(3)\n",
        "    \n",
        "    for _, row in recent_spikes.iterrows():\n",
        "        date = row['date']\n",
        "        price_change = row['price_change']\n",
        "        volume_z = row['volume_z_score']\n",
        "        \n",
        "        # For buy candidates\n",
        "        if direction == 'buy':\n",
        "            # Volume spike with positive price change\n",
        "            if price_change > 0 and volume_z > 2.5:\n",
        "                signals.append({\n",
        "                    'date': date,\n",
        "                    'signal': 'STRONG_BUY',\n",
        "                    'confidence': min(volume_z / 5, 1.0),\n",
        "                    'reason': f\"Volume spike (Z={volume_z:.2f}) with positive price change ({price_change:.2f}%)\"\n",
        "                })\n",
        "            # Volume spike with negative price change (potential reversal)\n",
        "            elif price_change < 0 and volume_z > 3.0:\n",
        "                signals.append({\n",
        "                    'date': date,\n",
        "                    'signal': 'POTENTIAL_REVERSAL',\n",
        "                    'confidence': min(volume_z / 6, 0.8),\n",
        "                    'reason': f\"Volume spike (Z={volume_z:.2f}) with negative price change ({price_change:.2f}%)\"\n",
        "                })\n",
        "        \n",
        "        # For short candidates\n",
        "        elif direction == 'short':\n",
        "            # Volume spike with negative price change\n",
        "            if price_change < 0 and volume_z > 2.5:\n",
        "                signals.append({\n",
        "                    'date': date,\n",
        "                    'signal': 'STRONG_SHORT',\n",
        "                    'confidence': min(volume_z / 5, 1.0),\n",
        "                    'reason': f\"Volume spike (Z={volume_z:.2f}) with negative price change ({price_change:.2f}%)\"\n",
        "                })\n",
        "            # Volume spike with positive price change (potential reversal)\n",
        "            elif price_change > 0 and volume_z > 3.0:\n",
        "                signals.append({\n",
        "                    'date': date,\n",
        "                    'signal': 'POTENTIAL_REVERSAL',\n",
        "                    'confidence': min(volume_z / 6, 0.8),\n",
        "                    'reason': f\"Volume spike (Z={volume_z:.2f}) with positive price change ({price_change:.2f}%)\"\n",
        "                })\n",
        "    \n",
        "    return signals\n",
        "\n",
        "# Generate signals\n",
        "signals = generate_signals(df, DIRECTION)\n",
        "\n",
        "# Display signals\n",
        "if signals:\n",
        "    print(f\"Generated {len(signals)} signals for ORCL:\")\n",
        "    for signal in signals:\n",
        "        print(f\"Date: {signal['date'].strftime('%Y-%m-%d')}\")\n",
        "        print(f\"Signal: {signal['signal']}\")\n",
        "        print(f\"Confidence: {signal['confidence']:.2f}\")\n",
        "        print(f\"Reason: {signal['reason']}\")\n",
        "        print(\"---\")\n",
        "else:\n",
        "    print(f\"No signals generated for ORCL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results to BigQuery\n",
        "\n",
        "Let's save our analysis results to BigQuery for the master notebook to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Prepare analysis results for BigQuery\n",
        "def prepare_analysis_results(df, signals, ticker, direction):\n",
        "    # Get the latest data point\n",
        "    latest = df.iloc[-1]\n",
        "    \n",
        "    # Get the latest signal if available\n",
        "    latest_signal = None\n",
        "    latest_confidence = 0.0\n",
        "    notes = \"\"\n",
        "    \n",
        "    if signals:\n",
        "        latest_signal = signals[0]['signal']\n",
        "        latest_confidence = signals[0]['confidence']\n",
        "        notes = signals[0]['reason']\n",
        "    \n",
        "    # Create results dataframe\n",
        "    results = pd.DataFrame({\n",
        "        'date': [latest['date']],\n",
        "        'ticker': [ticker],\n",
        "        'direction': [direction],\n",
        "        'signal': [latest_signal if latest_signal else 'NEUTRAL'],\n",
        "        'confidence': [latest_confidence],\n",
        "        'volume_score': [latest['volume_z_score']],\n",
        "        'is_spike': [latest['is_volume_spike']],\n",
        "        'spike_strength': [latest['volume_ratio'] if latest['is_volume_spike'] else 0],\n",
        "        'notes': [notes],\n",
        "        'notebook_url': [f\"https://colab.research.google.com/drive/your-notebook-id-for-{ticker}\"],\n",
        "        'timestamp': [datetime.now()]\n",
        "    })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Prepare analysis results\n",
        "results = prepare_analysis_results(df, signals, TICKER, DIRECTION)\n",
        "\n",
        "# Display results\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Save analysis results to BigQuery\n",
        "def save_to_bigquery(results, ticker):\n",
        "    # Save to stock-specific analysis table\n",
        "    analysis_table = f\"{DATASET}.stock_{ticker}_analysis\"\n",
        "    results.to_gbq(analysis_table, PROJECT_ID, if_exists='append')\n",
        "    \n",
        "    # Save to master summary table\n",
        "    summary_table = f\"{DATASET}.master_summary\"\n",
        "    results.to_gbq(summary_table, PROJECT_ID, if_exists='append')\n",
        "    \n",
        "    print(f\"Saved analysis results to BigQuery tables: {analysis_table} and {summary_table}\")\n",
        "\n",
        "# Uncomment to save results to BigQuery\n",
        "# save_to_bigquery(results, TICKER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook analyzed volume patterns and inefficiencies for ORCL.\n",
        "\n",
        "### Key Findings:\n",
        "- Number of volume spikes in the past year: 0\n",
        "- Latest volume Z-score: 0.0\n",
        "- Current signal: NEUTRAL\n",
        "\n",
        "### Next Steps:\n",
        "- Monitor for new volume spikes\n",
        "- Check the master summary notebook for a comparison with other stocks"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ORCL Volume Analysis",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
